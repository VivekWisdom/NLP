{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word Embeddings.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivekwisdom/NLP/blob/develop/Word%20Embeddings/Word_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQpx33Ew1iKn",
        "colab_type": "text"
      },
      "source": [
        "In an embedding, words are represented by dense vectors where a vector represents the projection of the word into a continuous vector space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv0KlZzw4IPr",
        "colab_type": "text"
      },
      "source": [
        "The position of a word within the vector space is learned from text and is based on the words that surround the word when it is used.\n",
        "\n",
        "The position of a word in the learned vector space is referred to as its embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWa6iRFr7YV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.preprocessing.text import one_hot, Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKHm8Cks113e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "docs = ['Well done!',\n",
        "\t\t'Good work',\n",
        "\t\t'Great effort',\n",
        "\t\t'nice work',\n",
        "\t\t'Excellent!',\n",
        "\t\t'Weak',\n",
        "\t\t'Poor effort!',\n",
        "\t\t'not good',\n",
        "\t\t'poor work',\n",
        "\t\t'Could have done better.']\n",
        "# define class labels\n",
        "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_zng7hI7Q7Z",
        "colab_type": "code",
        "outputId": "61994687-f1a2-4f77-de65-919a5d14c883",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# integer encode the documents\n",
        "vocab_size = 50\n",
        "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
        "print(encoded_docs)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4, 15], [43, 18], [41, 40], [17, 18], [22], [28], [8, 40], [42, 43], [8, 18], [23, 46, 15, 43]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc6K1NIa7_O7",
        "colab_type": "code",
        "outputId": "c8fe706a-b9c7-496d-b6d8-45f5487d4b8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# pad documents to a max length of 4 words\n",
        "max_length = 4\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "print(padded_docs)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 4 15  0  0]\n",
            " [43 18  0  0]\n",
            " [41 40  0  0]\n",
            " [17 18  0  0]\n",
            " [22  0  0  0]\n",
            " [28  0  0  0]\n",
            " [ 8 40  0  0]\n",
            " [42 43  0  0]\n",
            " [ 8 18  0  0]\n",
            " [23 46 15 43]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na9W4Odq7_KJ",
        "colab_type": "code",
        "outputId": "b11a3fa9-7e3c-4b23-d9c0-0e2972b46058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "# summarize the model\n",
        "print(model.summary())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 4, 8)              400       \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 433\n",
            "Trainable params: 433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I2knojP7-9J",
        "colab_type": "code",
        "outputId": "e7275bde-aede-4b7d-fae3-a7d57bb1141d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# fit the model\n",
        "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 100.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ne4Wfarq-KfP",
        "colab_type": "text"
      },
      "source": [
        "## Example of Using Pre-Trained GloVe Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzvaK44--J1s",
        "colab_type": "code",
        "outputId": "005a7827-2b83-4a30-a9cc-1178bce62782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "docs = ['Well done!',\n",
        "\t\t'Good work',\n",
        "\t\t'Great effort',\n",
        "\t\t'nice work',\n",
        "\t\t'Excellent!',\n",
        "\t\t'Weak',\n",
        "\t\t'Poor effort!',\n",
        "\t\t'not good',\n",
        "\t\t'poor work',\n",
        "\t\t'Could have done better.']\n",
        "# define class labels\n",
        "labels = np.array([1,1,1,1,1,0,0,0,0,0])\n",
        "# prepare tokenizer\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(docs)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "# integer encode the documents\n",
        "encoded_docs = t.texts_to_sequences(docs)\n",
        "print(encoded_docs)\n",
        "# pad documents to a max length of 4 words\n",
        "max_length = 4\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "print(padded_docs)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6, 2], [3, 1], [7, 4], [8, 1], [9], [10], [5, 4], [11, 3], [5, 1], [12, 13, 2, 14]]\n",
            "[[ 6  2  0  0]\n",
            " [ 3  1  0  0]\n",
            " [ 7  4  0  0]\n",
            " [ 8  1  0  0]\n",
            " [ 9  0  0  0]\n",
            " [10  0  0  0]\n",
            " [ 5  4  0  0]\n",
            " [11  3  0  0]\n",
            " [ 5  1  0  0]\n",
            " [12 13  2 14]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqBvAGtvmUsj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "2ca2b20d-47a2-4054-beb6-c6f6637bca31"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-26 12:43:51--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-09-26 12:43:51--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-09-26 12:43:52--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  18.2MB/s    in 47s     \n",
            "\n",
            "2019-09-26 12:44:39 (17.6 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgNdyypLmYEh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a491a100-3251-4eaf-84d9-1d30ddaa2208"
      },
      "source": [
        "!unzip glove*.zip"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87CR-TjImawk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ab6c38ff-c9a0-4e21-ed35-caacc2ab11b1"
      },
      "source": [
        "!ls\n",
        "!pwd"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\n",
            "glove.6B.200d.txt  glove.6B.50d.txt   sample_data\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fauju19Y-JZX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b73108bc-a97b-443b-e3e4-c22bba122556"
      },
      "source": [
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "f = open('glove.6B.100d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEPZ_1yo8kkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "for word, i in t.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3awoTsfnHGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Wtf8xZNnOxM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "58b78a7d-a397-43f4-8fb4-c1b693a8c495"
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False)\n",
        "model.add(e)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "# summarize the model\n",
        "print(model.summary())\n",
        "# fit the model\n",
        "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 4, 100)            1500      \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 401       \n",
            "=================================================================\n",
            "Total params: 1,901\n",
            "Trainable params: 401\n",
            "Non-trainable params: 1,500\n",
            "_________________________________________________________________\n",
            "None\n",
            "Accuracy: 100.000000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}